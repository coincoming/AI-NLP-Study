用bert完成ner
使用6层transformers，效果相对于使用lstm有明显提升。
第10轮结果：
average loss: 0.354414
PERSON类实体，准确率：0.896373, 召回率: 0.891753, F1: 0.894052
LOCATION类实体，准确率：0.896104, 召回率: 0.866109, F1: 0.880846
TIME类实体，准确率：0.919075, 召回率: 0.893258, F1: 0.905978
ORGANIZATION类实体，准确率：0.714286, 召回率: 0.842105, F1: 0.772942
Macro-F1: 0.863454
Micro-F1 0.874907
